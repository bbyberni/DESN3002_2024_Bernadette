{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# prerequisites\n",
    "import torch\n",
    "th = torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "to_tensor = lambda x: torch.tensor(x).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        # Generate random data for X with shape (N, 20)\n",
    "        self.X = X\n",
    "        # Generate random data for y with shape (N, 18, 10)\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: DATASET IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = th.randint(2, size=(500, 20)).to(th.float)\n",
    "y = th.rand(500,18,10)\n",
    "# Instantiate the dataset\n",
    "dataset = CustomDataset(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 450\n",
      "Test dataset size: 50\n"
     ]
    }
   ],
   "source": [
    "# Define the split sizes\n",
    "eval_percent = 0.10\n",
    "num_eval = int(len(dataset) * eval_percent)\n",
    "num_train = len(dataset) - num_eval\n",
    "\n",
    "# Randomly split the dataset into training and evaluation datasets\n",
    "train_dataset, test_dataset = random_split(dataset, [num_train, num_eval])\n",
    "\n",
    "print(f\"Training dataset size: {len(train_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")\n",
    "\n",
    "# Set batch size\n",
    "batch_size = 50\n",
    "\n",
    "# Create DataLoader for the training dataset\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Create DataLoader for the evaluation dataset\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "def save_models(models, folder_path):\n",
    "    # Create the directory if it doesn't exist\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "\n",
    "    # Save each model\n",
    "    for model in models:\n",
    "        model_name = type(model).__name__  # Get the class name of the model\n",
    "        file_path = os.path.join(folder_path, f\"{model_name}.pt\")\n",
    "        torch.save(model.state_dict(), file_path)\n",
    "\n",
    "    print(\"Models saved successfully.\")\n",
    "\n",
    "# Example usage:\n",
    "# save_models([model1, model2], \"/path/to/folder\")\n",
    "\n",
    "def load_models(model_objects, folder_path):\n",
    "    # Load the state dicts for each model\n",
    "    for model in model_objects:\n",
    "        model_name = type(model).__name__  # Get the class name of the model\n",
    "        file_path = os.path.join(folder_path, f\"{model_name}.pt\")\n",
    "        model.load_state_dict(torch.load(file_path))\n",
    "\n",
    "    print(\"Models loaded successfully.\")\n",
    "\n",
    "# Example usage:\n",
    "# load_models([model1, model2], \"/path/to/folder\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CustomConvNet(nn.Module):\n",
    "    def __init__(self, num_1d_layers=3, num_2d_layers=2):# num_channels=180):\n",
    "        super(CustomConvNet, self).__init__()\n",
    "        \n",
    "        # Define initial parameters for the 1D conv layers\n",
    "        initial_channels = 16  # Initial number of channels\n",
    "        self.shape_1d = 20\n",
    "        self.shape_2d = (18, 10)\n",
    "        \n",
    "        # 1D Convolutional Layers\n",
    "        self.conv1d_layers = nn.ModuleList()\n",
    "        in_channels = 1\n",
    "        for i in range(num_1d_layers - 1):\n",
    "            out_channels = initial_channels * (2 ** i)\n",
    "            self.conv1d_layers.append(nn.Sequential(\n",
    "                nn.Conv1d(in_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
    "                nn.BatchNorm1d(out_channels),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(0.1)  # Regularization\n",
    "            ))\n",
    "            in_channels = out_channels\n",
    "        \n",
    "        # Last 1D convolution to adjust the channel size exactly to num_channels\n",
    "        self.conv1d_layers.append(nn.Conv1d(in_channels, self.shape_2d[0] * self.shape_2d[1], \n",
    "                                            kernel_size=3, stride=1, padding=1))\n",
    "        #print(num_channels)\n",
    "        \n",
    "        # 2D Convolutional Layers\n",
    "        self.conv2d_layers = nn.ModuleList()\n",
    "        in_channels = self.shape_1d\n",
    "        for i in range(num_2d_layers):\n",
    "            out_channels = 32 if i < num_2d_layers - 1 else 1  # Final output channel set to 1\n",
    "            self.conv2d_layers.append(nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=1),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(0.2)  # Regularization\n",
    "            ))\n",
    "            in_channels = out_channels\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # Add channel dimension (N, 1, L) where L is the sequence length\n",
    "\n",
    "        # Apply 1D convolutions\n",
    "        for layer in self.conv1d_layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        # Reshape to 2D (N, C, 18, 10)\n",
    "        x = x.view(x.size(0), -1, 18, 10)  # -1 here will automatically adjust to num_channels\n",
    "        \n",
    "        # Apply 2D convolutions\n",
    "        for layer in self.conv2d_layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        return x.squeeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(model, optimizer, train_loader, losses, epochs=1000):\n",
    "    model.train()\n",
    "    losses_ = losses.setdefault('train',{})\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        loss, metric = 0., 0.\n",
    "        for iter, (inputs, targets) in enumerate(train_loader):\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = train_loss_func(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            metric = test_eval_func(outputs.detach(), targets)\n",
    "\n",
    "            loss += loss.detach()\n",
    "            metric += metric.detach()\n",
    "            \n",
    "        loss /= (iter + 1)\n",
    "        metric /= (iter + 1)\n",
    "        \n",
    "        losses_.setdefault('loss', []).append(loss.detach())\n",
    "        losses_.setdefault('metric', []).append(metric.detach())\n",
    "        losses_.setdefault('epoch', []).append(epoch)\n",
    "\n",
    "        if (epoch+1) % 5 == 0:\n",
    "            print(f'TRAIN | Epoch {epoch+1}, Loss: {loss.item():.4f}, Metric: {metric.item():.4f}')\n",
    "            test(model, epoch, losses)\n",
    "\n",
    "def test(model, epoch, losses):\n",
    "    _ = model.eval()\n",
    "    losses_ = losses.setdefault('test',{})\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        loss, metric = 0., 0.\n",
    "        for iter, (inputs, targets) in enumerate(test_loader):\n",
    "            outputs = model(inputs)\n",
    "            loss = train_loss_func(outputs.detach(), targets.detach()).detach()\n",
    "            metric = test_eval_func(outputs.detach(), targets.detach()).detach()\n",
    "            \n",
    "        loss /= (iter + 1)\n",
    "        metric /= (iter + 1)\n",
    "        losses_.setdefault('loss', []).append(loss)\n",
    "        losses_.setdefault('metric', []).append(metric)\n",
    "        losses_.setdefault('epoch', []).append(epoch)\n",
    "            \n",
    "    print(f'... TEST | Epoch {epoch+1}, Loss: {loss.item():.4f}, Metric: {metric.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MAPELoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MAPELoss, self).__init__()\n",
    "\n",
    "    def forward(self, y_true, y_pred):\n",
    "        epsilon = 1e-8\n",
    "        percentage_error = torch.abs((y_true - y_pred) / (torch.abs(y_true) + epsilon))\n",
    "        mape = torch.mean(percentage_error) * 100.0\n",
    "        return mape\n",
    "\n",
    "train_loss_func = nn.MSELoss()\n",
    "test_eval_func = MAPELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the model\n",
    "model = CustomConvNet(num_1d_layers=3, num_2d_layers=2)\n",
    "\n",
    "if False: # test the model\n",
    "    #print(model)\n",
    "    # Creating a dummy input tensor of shape (N, L), where L=20\n",
    "    input_tensor = torch.randn(5, 20)  # 5 examples, each 1 x 20\n",
    "    # Forward pass\n",
    "    output = model(input_tensor)\n",
    "    print(\"Output shape:\", output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN | Epoch 5, Loss: 0.0383, Metric: 376108416.0000\n",
      "... TEST | Epoch 5, Loss: 0.1364, Metric: 814548608.0000\n",
      "TRAIN | Epoch 10, Loss: 0.0280, Metric: 186502672.0000\n",
      "... TEST | Epoch 10, Loss: 0.1237, Metric: 808205248.0000\n",
      "TRAIN | Epoch 15, Loss: 0.0187, Metric: 10.8779\n",
      "... TEST | Epoch 15, Loss: 0.0842, Metric: 48.9720\n",
      "TRAIN | Epoch 20, Loss: 0.0187, Metric: 11.2362\n",
      "... TEST | Epoch 20, Loss: 0.0835, Metric: 50.1076\n",
      "TRAIN | Epoch 25, Loss: 0.0187, Metric: 11.1956\n",
      "... TEST | Epoch 25, Loss: 0.0834, Metric: 49.8896\n",
      "TRAIN | Epoch 30, Loss: 0.0186, Metric: 11.1378\n",
      "... TEST | Epoch 30, Loss: 0.0834, Metric: 49.8627\n",
      "TRAIN | Epoch 35, Loss: 0.0185, Metric: 11.0836\n",
      "... TEST | Epoch 35, Loss: 0.0834, Metric: 49.8231\n",
      "TRAIN | Epoch 40, Loss: 0.0183, Metric: 11.1202\n",
      "... TEST | Epoch 40, Loss: 0.0834, Metric: 50.0494\n",
      "TRAIN | Epoch 45, Loss: 0.0184, Metric: 11.0635\n",
      "... TEST | Epoch 45, Loss: 0.0834, Metric: 49.7300\n",
      "TRAIN | Epoch 50, Loss: 0.0185, Metric: 11.1098\n",
      "... TEST | Epoch 50, Loss: 0.0834, Metric: 49.9558\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/0k/sjz1x0_n7_12_0wk4kxdkw9w0000gs/T/ipykernel_13241/3286463784.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/0k/sjz1x0_n7_12_0wk4kxdkw9w0000gs/T/ipykernel_13241/648457649.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, optimizer, train_loader, losses, epochs)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/kmmt_new_llm/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/0k/sjz1x0_n7_12_0wk4kxdkw9w0000gs/T/ipykernel_13241/4206183901.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;31m# Apply 2D convolutions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/kmmt_new_llm/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/kmmt_new_llm/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/kmmt_new_llm/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/kmmt_new_llm/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/kmmt_new_llm/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    457\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 459\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    460\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "losses = {}\n",
    "train_model(model, optimizer, train_loader, losses,  epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Example usage:\n",
    "# load_models([model1, model2], \"/path/to/folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting the loss\n",
    "fig, ax = plt.subplots(figsize=(10,4))\n",
    "key='loss'\n",
    "ax.plot(losses['train']['epoch'], losses['train'][key], label='Train Loss', c='blue')\n",
    "ax.plot(losses['test']['epoch'], losses['test'][key], label='Test Loss', c='red')\n",
    "\n",
    "# Adding labels and title\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_title('Training and Test Loss')\n",
    "\n",
    "# Adding legend\n",
    "ax.legend()\n",
    "\n",
    "# Displaying the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def sort_and_show_data(data, objective):\n",
    "    # Sort data based on objective vector\n",
    "    sorted_indices = np.argsort(objective)[::-1]\n",
    "    sorted_data = data[sorted_indices][:10]\n",
    "    sorted_objective = objective[sorted_indices][:10]\n",
    "\n",
    "    # Plot sorted data\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    # Plot sorted data as image with flipped orientation\n",
    "    ax1.imshow(sorted_data[::-1], cmap='binary', aspect='auto', extent=[0, 20, 0, len(sorted_data)])\n",
    "    \n",
    "    # Set labels and ticks for ax1\n",
    "    ax1.set_xticks([])\n",
    "    ax1.set_yticks(np.arange(0, 11, 2))\n",
    "    ax1.set_yticklabels(np.arange(10, -1, -2))\n",
    "    ax1.set_ylabel('Sample Index')\n",
    "    ax1.set_xlabel('Feature Index')\n",
    "    ax1.grid(axis='y', linestyle='--')\n",
    "\n",
    "    print(sorted_objective)\n",
    "    # Plot circles representing the objective vector with flipped orientation\n",
    "    ax2.set_xlim(0, 10)\n",
    "    ax2.set_ylim(0, 10)\n",
    "    for i, val in enumerate(sorted_objective):\n",
    "        ax2.add_patch(plt.Circle((5, i + 0.5), val * 1, color='red', fill=False))\n",
    "\n",
    "    # Set labels and ticks for ax2\n",
    "    ax2.set_xticks(np.arange(1, 11))\n",
    "    ax2.set_yticks([])\n",
    "    ax2.set_xlabel('Sorted Objective Value')\n",
    "    ax2.set_aspect('equal')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# Assuming you have data of shape (n, 20) and objective vector of shape (n, 1)\n",
    "n = 100  # Number of samples\n",
    "data = np.random.randint(0, 2, size=(n, 20))  # Example binary data\n",
    "objective = np.random.rand(n)  # Example objective vector\n",
    "sort_and_show_data(data, objective)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
